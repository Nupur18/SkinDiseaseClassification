{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e5c7697",
      "metadata": {
        "id": "1e5c7697"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications.densenet import DenseNet201\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYCgLwABPPu6",
        "outputId": "210eec56-25c8-4766-b467-01b15db5a19e"
      },
      "id": "aYCgLwABPPu6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d7a7389",
      "metadata": {
        "id": "4d7a7389"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "def send_to_telegram(*args):\n",
        "\n",
        "    apiToken = '6134697656:AAFAowB-BC50S3of4BxU2WgGfPLQFLCKdWg'\n",
        "    chatID = '1213767748'\n",
        "    apiURL = f'https://api.telegram.org/bot{apiToken}/sendMessage'\n",
        "    message = \" \".join(map(lambda x:str(x),args))\n",
        "    try:\n",
        "        response = requests.post(apiURL, json={'chat_id': chatID, 'text': message})\n",
        "    except Exception as e:\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "762b3d00",
      "metadata": {
        "id": "762b3d00"
      },
      "outputs": [],
      "source": [
        "PROJECT_PATH = \"/content/drive/MyDrive/Project - II/Ensemble Files\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37c778a6",
      "metadata": {
        "id": "37c778a6"
      },
      "outputs": [],
      "source": [
        "EPOCHS=1\n",
        "POPULATION_SIZE = 25\n",
        "NO_OF_ITERATIONS = 20\n",
        "LOWER_BOUND = 0.0\n",
        "UPPER_BOUND = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab870801",
      "metadata": {
        "id": "ab870801"
      },
      "outputs": [],
      "source": [
        "# out_vec = np.load(\"Ensemble/balancedX_256_192.npy\")\n",
        "# out_vec = out_vec.astype(\"float32\")\n",
        "# out_vec /= 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e078458",
      "metadata": {
        "id": "0e078458"
      },
      "outputs": [],
      "source": [
        "# labels = np.load(\"Ensemble/balancedY_256_192.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98bd56ae",
      "metadata": {
        "id": "98bd56ae"
      },
      "outputs": [],
      "source": [
        "# print(out_vec.shape)\n",
        "# print(labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.load(\"/content/drive/MyDrive/Project - II/Balanced Data 256_192/X_test.npy\")\n",
        "X_val = np.load(\"/content/drive/MyDrive/Project - II/Balanced Data 256_192/X_val.npy\")\n",
        "\n",
        "y_train = np.load(\"/content/drive/MyDrive/Project - II/Balanced Data 256_192/y_test.npy\")\n",
        "y_val = np.load(\"/content/drive/MyDrive/Project - II/Balanced Data 256_192/y_val.npy\")"
      ],
      "metadata": {
        "id": "54C95Q44PzNM"
      },
      "id": "54C95Q44PzNM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc577d98",
      "metadata": {
        "id": "fc577d98"
      },
      "outputs": [],
      "source": [
        "X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train = X_train[:1000]\n",
        "# X_val = X_val[:200]\n",
        "# y_train = y_train[:1000]\n",
        "# y_val = y_val[:200]"
      ],
      "metadata": {
        "id": "ZrvD76pdjQ1o"
      },
      "id": "ZrvD76pdjQ1o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7552f15",
      "metadata": {
        "id": "e7552f15"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import *\n",
        "\n",
        "ranges = {\n",
        "  \"Batch Size\": [32,64,128],\n",
        "  \"amsgrad\":[True,False],\n",
        "  \"weight_decay\":[None,1e-5,1e-6],\n",
        "  \"lr\":  np.geomspace(1e-3,1e-5,3),\n",
        "  \"b1\":np.arange(0.8,0.96,0.05),\n",
        "  \"b2\":np.arange(0.990,0.9991,0.003),\n",
        "  \"epsilon\":[1e-7,1e-8],\n",
        "  \"factor\":[0.1,0.2,0.5],\n",
        "  \"patience\": [2,3,5],\n",
        "  \"cooldown\":[2,3,5]\n",
        "}\n",
        "\n",
        "SOLUTION_SIZE = len(ranges.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6f1855b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6f1855b",
        "outputId": "2b5e2004-adeb-4b2c-c3cc-76c6bada0961"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25, 10)\n",
            "[0.2149059  0.44113276 0.82625773 0.18097418 0.57050742 0.41529574\n",
            " 0.81226586 0.53128705 0.99972521 0.01372609]\n"
          ]
        }
      ],
      "source": [
        "# Population Initialization\n",
        "population = np.random.uniform(\n",
        "  low=LOWER_BOUND,\n",
        "  high=UPPER_BOUND,\n",
        "  size=(POPULATION_SIZE, SOLUTION_SIZE)\n",
        ")\n",
        "print(population.shape)\n",
        "print(population[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b9b2780",
      "metadata": {
        "id": "8b9b2780"
      },
      "outputs": [],
      "source": [
        "# Fitness Function Evaluation\n",
        "def FitnessFunction(solution):\n",
        "  solution = np.round(solution, 4)\n",
        "\n",
        "  index = int(np.round(solution[0] * (len(ranges[\"Batch Size\"]) - 1)))\n",
        "  batchSizeValue = ranges[\"Batch Size\"][index]\n",
        "\n",
        "  index = int(np.round(solution[1] * (len(ranges[\"amsgrad\"]) - 1)))\n",
        "  amsgrad = ranges[\"amsgrad\"][index]\n",
        "\n",
        "  index = int(np.round(solution[2] * (len(ranges[\"weight_decay\"]) - 1)))\n",
        "  weight_decay = ranges[\"weight_decay\"][index]\n",
        "\n",
        "  index = int(np.round(solution[3] * (len(ranges[\"lr\"]) - 1)))\n",
        "  lr = ranges[\"lr\"][index]\n",
        "\n",
        "  index = int(np.round(solution[4] * (len(ranges[\"b1\"]) - 1)))\n",
        "  b1 = ranges[\"b1\"][index]\n",
        "\n",
        "  index = int(np.round(solution[5] * (len(ranges[\"b2\"]) - 1)))\n",
        "  b2 = ranges[\"b2\"][index]\n",
        "\n",
        "\n",
        "  index = int(np.round(solution[6] * (len(ranges[\"epsilon\"]) - 1)))\n",
        "  epsilon = ranges[\"epsilon\"][index]\n",
        "\n",
        "\n",
        "  index = int(np.round(solution[7] * (len(ranges[\"factor\"]) - 1)))\n",
        "  factor = ranges[\"factor\"][index]\n",
        "\n",
        "\n",
        "  index = int(np.round(solution[8] * (len(ranges[\"patience\"]) - 1)))\n",
        "  patience = ranges[\"patience\"][index]\n",
        "\n",
        "\n",
        "  index = int(np.round(solution[9] * (len(ranges[\"cooldown\"]) - 1)))\n",
        "  cooldown = ranges[\"cooldown\"][index]\n",
        "\n",
        "  # Training Densenet\n",
        "  pre_trained_densenet_model = DenseNet201(input_shape=(192, 256, 3), include_top=False, weights=\"imagenet\")\n",
        "\n",
        "  for layer in pre_trained_densenet_model.layers:\n",
        "      layer.trainable = False\n",
        "\n",
        "  last_layer = pre_trained_densenet_model.get_layer('relu')\n",
        "  last_output = last_layer.output\n",
        "  x = layers.GlobalMaxPooling2D()(last_output)\n",
        "  x = layers.Dense(512, activation='relu')(x)\n",
        "  x = layers.Dropout(0.5)(x)\n",
        "  x = layers.Dense(7, activation='softmax')(x)\n",
        "\n",
        "  densenet_model = Model(pre_trained_densenet_model.input, x)\n",
        "  optimizer = Adam(learning_rate=lr, beta_1=b1, beta_2=b2, epsilon=epsilon, weight_decay=weight_decay, amsgrad=amsgrad)\n",
        "  densenet_model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  train_datagen = ImageDataGenerator(rotation_range=60, width_shift_range=0.2, height_shift_range=0.2,\n",
        "                                   shear_range=0.2, zoom_range=0.2, fill_mode='nearest')\n",
        "\n",
        "  train_datagen.fit(X_train)\n",
        "\n",
        "  val_datagen = ImageDataGenerator()\n",
        "  val_datagen.fit(X_val)\n",
        "  epochs = 1\n",
        "  densenet_model.fit(train_datagen.flow(X_train,y_train, batch_size=batchSizeValue),\n",
        "                                epochs = epochs, validation_data = val_datagen.flow(X_val, y_val),\n",
        "                                verbose = 1, steps_per_epoch=(X_train.shape[0] // batchSizeValue), \n",
        "                                validation_steps=(X_val.shape[0] // batchSizeValue))\n",
        "  \n",
        "  for layer in pre_trained_densenet_model.layers:\n",
        "      layer.trainable = True\n",
        "  optimizer = Adam(learning_rate=lr, beta_1=b1, beta_2=b2, epsilon=epsilon, weight_decay=weight_decay, amsgrad=amsgrad)\n",
        "  densenet_model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['acc'])\n",
        "  \n",
        "  learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=patience, verbose=1, factor=factor, \n",
        "                                            min_lr=lr/10, cooldown=cooldown)\n",
        "\n",
        "  epochs = EPOCHS\n",
        "  densenet_model.fit(train_datagen.flow(X_train,y_train, batch_size=batchSizeValue),\n",
        "                                epochs = epochs, validation_data = val_datagen.flow(X_val, y_val),\n",
        "                                verbose = 1, steps_per_epoch=(X_train.shape[0] // batchSizeValue),\n",
        "                                validation_steps=(X_val.shape[0] // batchSizeValue),\n",
        "                                callbacks=[learning_rate_reduction])\n",
        "  \n",
        "  # Training inception\n",
        "  pre_trained_inception_model = InceptionV3(input_shape=(192, 256, 3), include_top=False, weights=\"imagenet\")\n",
        "\n",
        "  for layer in pre_trained_inception_model.layers:\n",
        "      layer.trainable = False\n",
        "\n",
        "  last_layer = pre_trained_inception_model.get_layer('mixed10')\n",
        "  last_output = last_layer.output\n",
        "  x = layers.GlobalMaxPooling2D()(last_output)\n",
        "  x = layers.Dense(512, activation='relu')(x)\n",
        "  x = layers.Dropout(0.5)(x)\n",
        "  x = layers.Dense(7, activation='softmax')(x)\n",
        "\n",
        "  inception_model = Model(pre_trained_inception_model.input, x)\n",
        "  optimizer = Adam(learning_rate=lr, beta_1=b1, beta_2=b2, epsilon=epsilon, weight_decay=weight_decay, amsgrad=amsgrad)\n",
        "  inception_model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  epochs = 1\n",
        "  history = inception_model.fit(train_datagen.flow(X_train,y_train, batch_size=batchSizeValue),\n",
        "                                epochs = epochs, validation_data = val_datagen.flow(X_val, y_val),\n",
        "                                verbose = 1, steps_per_epoch=(X_train.shape[0] // batchSizeValue), \n",
        "                                validation_steps=(X_val.shape[0] // batchSizeValue))\n",
        "  \n",
        "  for layer in pre_trained_inception_model.layers:\n",
        "      layer.trainable = True\n",
        "\n",
        "  optimizer = Adam(learning_rate=lr, beta_1=b1, beta_2=b2, epsilon=epsilon, weight_decay=weight_decay, amsgrad=amsgrad)\n",
        "  inception_model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['acc'])\n",
        "  \n",
        "  learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=patience, verbose=1, factor=factor, \n",
        "                                            min_lr=lr/10, cooldown=cooldown)\n",
        "\n",
        "  epochs = EPOCHS\n",
        "  history = inception_model.fit(train_datagen.flow(X_train,y_train, batch_size=batchSizeValue),\n",
        "                                epochs = epochs, validation_data = val_datagen.flow(X_val, y_val),\n",
        "                                verbose = 1, steps_per_epoch=(X_train.shape[0] // batchSizeValue),\n",
        "                                validation_steps=(X_val.shape[0] // batchSizeValue),\n",
        "                                callbacks=[learning_rate_reduction])\n",
        "  \n",
        "  # def ensemble(models, model_input):\n",
        "\n",
        "  #     outputs = [model.outputs[0] for model in models]\n",
        "  #     y = layers.Average()(outputs)\n",
        "  #     model = Model(model_input, y, name='ensemble')\n",
        "  #     return model\n",
        "\n",
        "  input_shape = X_val[0,:,:,:].shape\n",
        "  model_input = layers.Input(shape=input_shape)\n",
        "\n",
        "  dense_output = densenet_model(model_input)\n",
        "  inception_output = inception_model(model_input)\n",
        "  y = layers.Average()([dense_output,inception_output])\n",
        "\n",
        "  # ensemble_model = ensemble([densenet_model, inception_model], model_input)\n",
        "\n",
        "  ensemble_model = Model(model_input,y,name=\"ensemble\")\n",
        "  ensemble_model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        "  \n",
        "  keyword = \"ensemble-\" + \"-\".join([str(el)[2:] for el in solution])\n",
        "  checkpointPath = os.path.join(PROJECT_PATH, \"Checkpoints\", keyword) + \".h5\"\n",
        "  csvLogPath = os.path.join(PROJECT_PATH, \"Logs\", keyword) + \".csv\"\n",
        "\n",
        "  loss_val, acc_val = ensemble_model.evaluate(X_val, y_val, verbose=2)\n",
        "  # score = scoreList[0]\n",
        "\n",
        "  configs = [\n",
        "    batchSizeValue,\n",
        "    amsgrad,\n",
        "    weight_decay,\n",
        "    lr,\n",
        "    b1,\n",
        "    b2,\n",
        "    epsilon,\n",
        "    factor,\n",
        "    patience,\n",
        "    cooldown,\n",
        "  ]\n",
        "  # print(score, configs)\n",
        "  print(\"Validation: accuracy = %f ;  loss = %f\" % (acc_val, loss_val))\n",
        "  send_to_telegram(\"Validation: accuracy = %f ;  loss = %f\" % (acc_val, loss_val))\n",
        "  send_to_telegram(\"Configs\", configs)\n",
        "  # send_to_telegram(score, configs)\n",
        "\n",
        "  return acc_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bb2fa13",
      "metadata": {
        "id": "2bb2fa13"
      },
      "outputs": [],
      "source": [
        "# Population Updating\n",
        "def PopulationUpdating(population, scores, iterationNumber):\n",
        "  bestIndex = np.argmax(scores)\n",
        "  bestSolution = population[bestIndex].copy()\n",
        "  bestScore = scores[bestIndex]\n",
        "\n",
        "  # MRFO:\n",
        "  # Write the metaheuristic rules for updating the population.\n",
        "  newPopulation = population.copy()\n",
        "\n",
        "  coef = iterationNumber / float(NO_OF_ITERATIONS)\n",
        "  for i in range(len(population)):\n",
        "    r = np.random.random(1)\n",
        "    alpha = 2.0 * r * np.sqrt(np.abs(np.log(r)))\n",
        "    r1 = np.random.random(1)\n",
        "    factor = (NO_OF_ITERATIONS - iterationNumber + 1.0) / (NO_OF_ITERATIONS * 1.0)\n",
        "    beta = 2.0 * np.exp(r1 * factor) * np.sin(2.0 * np.pi * r1)\n",
        "    if (np.random.random(1) < 0.5):\n",
        "      if (coef < np.random.random(1)):\n",
        "        s = np.subtract(UPPER_BOUND, LOWER_BOUND)\n",
        "        u = np.random.uniform(low=0, high=1, size=SOLUTION_SIZE)\n",
        "        m = np.multiply(u, s)\n",
        "        xRand = np.clip(np.add(LOWER_BOUND, m), LOWER_BOUND, UPPER_BOUND)\n",
        "        if (i == 0):\n",
        "          newPopulation[i, :] = xRand + r * (xRand - population[i, :]) + beta * (xRand - population[i, :])\n",
        "        else:\n",
        "          newPopulation[i, :] = xRand + r * (population[i - 1, :] - population[i, :]) + beta * (xRand - population[i, :])\n",
        "      else:\n",
        "        if (i == 0):\n",
        "          newPopulation[i, :] = bestSolution + r * (bestSolution - population[i, :]) + beta * (bestSolution - population[i, :])\n",
        "        else:\n",
        "          newPopulation[i, :] = bestSolution + r * (population[i - 1, :] - population[i, :]) + beta * (bestSolution - population[i, :])\n",
        "    else:\n",
        "      if (i == 0):\n",
        "        newPopulation[i, :] = population[i, :] + r * (bestSolution - population[i, :]) + alpha * (bestSolution - population[i, :])\n",
        "      else:\n",
        "        newPopulation[i, :] = population[i, :] + r * (population[i - 1, :] - population[i, :]) + alpha * (bestSolution - population[i, :])\n",
        "    \n",
        "    newPopulation[i, :] = np.clip(newPopulation[i, :], LOWER_BOUND, UPPER_BOUND)\n",
        "    \n",
        "    currentScore = FitnessFunction(newPopulation[i, :])\n",
        "    if (currentScore > bestScore):\n",
        "      bestSolution, bestScore = newPopulation[i, :].copy(), currentScore\n",
        "    \n",
        "    s = 2.0\n",
        "    r2, r3 = np.random.random(1), np.random.random(1)\n",
        "    newPopulation[i, :] = population[i, :] + s * (r2 * bestSolution - r3 * population[i, :])\n",
        "    \n",
        "    newPopulation[i, :] = np.clip(newPopulation[i, :], LOWER_BOUND, UPPER_BOUND)\n",
        "    \n",
        "    currentScore = FitnessFunction(newPopulation[i, :])\n",
        "    if (currentScore > bestScore):\n",
        "      bestSolution, bestScore = newPopulation[i, :].copy(), currentScore\n",
        "\n",
        "  return newPopulation.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad49099e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad49099e",
        "outputId": "01d001e3-66fa-401d-e828-26b8fb38b9ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration-0 population-0\n",
            "31/31 [==============================] - 27s 509ms/step - loss: 3.6343 - accuracy: 0.2149 - val_loss: 1.7465 - val_accuracy: 0.3177\n",
            "31/31 [==============================] - 148s 727ms/step - loss: 1.9684 - acc: 0.3595 - val_loss: 42.2885 - val_acc: 0.1198 - lr: 0.0010\n",
            "31/31 [==============================] - 17s 420ms/step - loss: 5.0933 - accuracy: 0.1694 - val_loss: 1.8407 - val_accuracy: 0.2292\n",
            "31/31 [==============================] - 54s 485ms/step - loss: 1.8423 - acc: 0.2603 - val_loss: 13.2678 - val_acc: 0.1198 - lr: 0.0010\n",
            "7/7 - 10s - loss: 8.9434 - accuracy: 0.1150 - 10s/epoch - 1s/step\n",
            "Validation: accuracy = 0.115000 ;  loss = 8.943394\n",
            "iteration-0 population-1\n",
            "31/31 [==============================] - 27s 514ms/step - loss: 3.3844 - accuracy: 0.2707 - val_loss: 1.5554 - val_accuracy: 0.3490\n",
            "31/31 [==============================] - 152s 692ms/step - loss: 1.8731 - acc: 0.3481 - val_loss: 1572.4404 - val_acc: 0.1094 - lr: 0.0010\n",
            "31/31 [==============================] - 18s 426ms/step - loss: 4.4898 - accuracy: 0.1932 - val_loss: 1.9338 - val_accuracy: 0.2031\n",
            "31/31 [==============================] - 55s 486ms/step - loss: 2.0131 - acc: 0.1983 - val_loss: 2598.9534 - val_acc: 0.1250 - lr: 0.0010\n",
            "7/7 - 9s - loss: 12.4161 - accuracy: 0.1250 - 9s/epoch - 1s/step\n",
            "Validation: accuracy = 0.125000 ;  loss = 12.416108\n",
            "iteration-0 population-2\n",
            "31/31 [==============================] - 34s 592ms/step - loss: 4.3195 - accuracy: 0.1322 - val_loss: 2.7896 - val_accuracy: 0.1510\n",
            "31/31 [==============================] - 142s 672ms/step - loss: 5.3531 - acc: 0.1426 - val_loss: 2.4618 - val_acc: 0.1302 - lr: 1.0000e-05\n",
            "31/31 [==============================] - 18s 425ms/step - loss: 4.7448 - accuracy: 0.1364 - val_loss: 2.7797 - val_accuracy: 0.0885\n",
            "31/31 [==============================] - 68s 482ms/step - loss: 3.6971 - acc: 0.1519 - val_loss: 2.6250 - val_acc: 0.1302 - lr: 1.0000e-05\n"
          ]
        }
      ],
      "source": [
        "# Repeat\n",
        "bestSolutions = []\n",
        "bestScores = []\n",
        "for iterationNumber in range(NO_OF_ITERATIONS):\n",
        "  scores = []\n",
        "  send_to_telegram(f\"{iterationNumber} Started\")\n",
        "  for i in range(len(population)):\n",
        "    print(f\"iteration-{iterationNumber} population-{i}\")\n",
        "    score = FitnessFunction(population[i])\n",
        "    send_to_telegram(f\"iteration-{iterationNumber} population-{i} Done\")\n",
        "    scores.append(score)\n",
        "\n",
        "  newPopulation = PopulationUpdating(population, scores, iterationNumber)\n",
        "  \n",
        "  # LOGGING THE DATA\n",
        "  populationScoresPath = os.path.join(PROJECT_PATH, \"Population.csv\")\n",
        "  # T #, S #, ......, Score\n",
        "  file = open(populationScoresPath, \"a\")\n",
        "  for i in range(len(population)):\n",
        "    data = f\"{iterationNumber + 1},{i + 1},\"\n",
        "    data += \",\".join([str(el) for el in population[i]])\n",
        "    data += f\",{scores[i]}\"\n",
        "    data += \"\\n\"\n",
        "    file.write(data)\n",
        "  file.close()\n",
        "\n",
        "  bestIndex = np.argmax(scores)\n",
        "  bestSolution = population[bestIndex].copy()\n",
        "  bestScore = scores[bestIndex]\n",
        "  bestSolutions.append(bestSolution)\n",
        "  bestScores.append(bestScore)\n",
        "  \n",
        "  population = newPopulation.copy()\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22028550",
      "metadata": {
        "id": "22028550"
      },
      "outputs": [],
      "source": [
        "# LOGGING THE DATA\n",
        "bestSolutionsPath = os.path.join(PROJECT_PATH, \"BestSolutions.csv\")\n",
        "file = open(bestSolutionsPath, \"w\")\n",
        "for i in range(len(bestSolutions)):\n",
        "  data = \",\".join([str(el) for el in bestSolutions[i]])\n",
        "  data += f\",{bestScores[i]}\"\n",
        "  data += \"\\n\"\n",
        "  file.write(data)\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7aac9144",
      "metadata": {
        "id": "7aac9144"
      },
      "outputs": [],
      "source": [
        "print(bestSolutions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57123b12",
      "metadata": {
        "id": "57123b12"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d3219c1",
      "metadata": {
        "id": "4d3219c1"
      },
      "outputs": [],
      "source": [
        "bestSolutions = pd.read_csv(os.path.join(PROJECT_PATH,\"BestSolutions.csv\"), header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0944bfb",
      "metadata": {
        "id": "c0944bfb"
      },
      "outputs": [],
      "source": [
        "bestSolutions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80a0d92f",
      "metadata": {
        "id": "80a0d92f"
      },
      "outputs": [],
      "source": [
        "bestSolutions = bestSolutions.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96cc61e0",
      "metadata": {
        "id": "96cc61e0"
      },
      "outputs": [],
      "source": [
        "bestSolutions.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97bc87d8",
      "metadata": {
        "id": "97bc87d8"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f52869c",
      "metadata": {
        "id": "3f52869c"
      },
      "outputs": [],
      "source": [
        "for i in range(len(bestSolutions)):\n",
        "    solution = np.round(bestSolutions[i], 4)\n",
        "\n",
        "    index = int(np.round(solution[0] * (len(ranges[\"Batch Size\"]) - 1)))\n",
        "    batchSizeValue = ranges[\"Batch Size\"][index]\n",
        "\n",
        "    index = int(np.round(solution[1] * (len(ranges[\"amsgrad\"]) - 1)))\n",
        "    amsgrad = ranges[\"amsgrad\"][index]\n",
        "\n",
        "    index = int(np.round(solution[2] * (len(ranges[\"weight_decay\"]) - 1)))\n",
        "    weight_decay = ranges[\"weight_decay\"][index]\n",
        "\n",
        "    index = int(np.round(solution[3] * (len(ranges[\"lr\"]) - 1)))\n",
        "    lr = ranges[\"lr\"][index]\n",
        "\n",
        "    index = int(np.round(solution[4] * (len(ranges[\"b1\"]) - 1)))\n",
        "    b1 = ranges[\"b1\"][index]\n",
        "\n",
        "    index = int(np.round(solution[5] * (len(ranges[\"b2\"]) - 1)))\n",
        "    b2 = ranges[\"b2\"][index]\n",
        "\n",
        "\n",
        "    index = int(np.round(solution[6] * (len(ranges[\"epsilon\"]) - 1)))\n",
        "    epsilon = ranges[\"epsilon\"][index]\n",
        "\n",
        "\n",
        "    index = int(np.round(solution[7] * (len(ranges[\"factor\"]) - 1)))\n",
        "    factor = ranges[\"factor\"][index]\n",
        "\n",
        "\n",
        "    index = int(np.round(solution[8] * (len(ranges[\"patience\"]) - 1)))\n",
        "    patience = ranges[\"patience\"][index]\n",
        "\n",
        "\n",
        "    index = int(np.round(solution[9] * (len(ranges[\"cooldown\"]) - 1)))\n",
        "    cooldown = ranges[\"cooldown\"][index]\n",
        "    \n",
        "    configs = [\n",
        "      batchSizeValue,\n",
        "      amsgrad,\n",
        "      weight_decay,\n",
        "      lr,\n",
        "      b1,\n",
        "      b2,\n",
        "      epsilon,\n",
        "      factor,\n",
        "      patience,\n",
        "      cooldown,\n",
        "    ]\n",
        "    print(configs, \"Accuarcy =\", solution[10])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}